#!/bin/bash

echo "========================================="
echo "  MiniELM å®Œæ•´è®­ç»ƒæµç¨‹"
echo "========================================="

# 1. ä¸‹è½½æ•°æ®
echo -e "\nğŸ“¥ æ­¥éª¤1: ä¸‹è½½ESCIæ•°æ®é›†..."
python data/download_esci.py

# 2. æ„å»ºQ2Qæ•°æ®é›†
echo -e "\nğŸ”¨ æ­¥éª¤2: æ„å»ºQ2Qæ•°æ®é›†..."
python data/build_q2q.py

# 3. å¯åŠ¨Elasticsearch (å¦‚æœæœªå¯åŠ¨)
echo -e "\nğŸ” æ­¥éª¤3: æ£€æŸ¥Elasticsearch..."
if ! curl -s http://localhost:9200 > /dev/null; then
    echo "å¯åŠ¨Elasticsearch..."
    docker run -d -p 9200:9200 -e "discovery.type=single-node" docker.elastic.co/elasticsearch/elasticsearch:8.10.0
    sleep 30
fi

# 4. ç´¢å¼•å•†å“æ•°æ®
echo -e "\nğŸ“¦ æ­¥éª¤4: ç´¢å¼•å•†å“æ•°æ®..."
python data/setup_elasticsearch.py

# 5. è®­ç»ƒç›¸å…³æ€§æ¨¡å‹
echo -e "\nğŸ¯ æ­¥éª¤5: è®­ç»ƒç›¸å…³æ€§è¯„åˆ†æ¨¡å‹..."
python models/relevance_scorer.py

# 6. SFTè®­ç»ƒStudent
echo -e "\nğŸ’ æ­¥éª¤6: SFTè®­ç»ƒStudentæ¨¡å‹..."
python training/sft_trainer.py

# 7. çŸ¥è¯†è’¸é¦
echo -e "\nğŸ”¬ æ­¥éª¤7: çŸ¥è¯†è’¸é¦..."
python -c "
from training.distillation import DistillationTrainer
from training.sft_trainer import SFTTrainer
import yaml

with open('config/config.yaml', 'r') as f:
    config = yaml.safe_load(f)

# åŠ è½½æ•°æ®
trainer = SFTTrainer(config['models']['student']['name'])
train_data, val_data = trainer.load_q2q_data()

# è’¸é¦
distiller = DistillationTrainer(
    teacher_path='./checkpoints/teacher_sft',
    student_path='./checkpoints/student_sft'
)
# TODO: éœ€è¦å‡†å¤‡dataloader
print('è¯·è¿è¡Œå®Œæ•´çš„Pythonè„šæœ¬è¿›è¡Œè’¸é¦')
"

# 8. åœ¨çº¿DPOè®­ç»ƒ
echo -e "\nğŸ® æ­¥éª¤8: åœ¨çº¿DPOè®­ç»ƒ..."
python training/online_dpo.py

# 9. è¯„ä¼°
echo -e "\nğŸ“Š æ­¥éª¤9: è¯„ä¼°æ¨¡å‹..."
python evaluation/evaluator.py

echo -e "\nâœ… å®Œæ•´æµç¨‹æ‰§è¡Œå®Œæ¯•ï¼"
echo "æŸ¥çœ‹ç»“æœ: ./outputs/"