"""
ç›¸å…³æ€§è¯„åˆ†æ¨¡å‹ï¼ˆè®ºæ–‡ä¸­çš„M1ï¼‰
åŸºäºBERTå¾®è°ƒï¼Œç”¨äºè¯„ä¼°query-productç›¸å…³æ€§
"""

import torch
import torch.nn as nn
from transformers import BertForSequenceClassification, BertTokenizer, Trainer, TrainingArguments
from datasets import Dataset
import numpy as np

class RelevanceScorer:
    def __init__(self, model_name: str = "bert-base-uncased"):
        """åˆå§‹åŒ–ç›¸å…³æ€§è¯„åˆ†å™¨"""
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # åŠ è½½BERTæ¨¡å‹ï¼ˆ4åˆ†ç±»ï¼šE, S, C, Iï¼‰
        self.model = BertForSequenceClassification.from_pretrained(
            model_name,
            num_labels=4
        ).to(self.device)
        
        self.tokenizer = BertTokenizer.from_pretrained(model_name)
        
        # æ ‡ç­¾æ˜ å°„
        self.label_to_id = {'E': 0, 'S': 1, 'C': 2, 'I': 3}
        self.id_to_label = {v: k for k, v in self.label_to_id.items()}
        
        # åˆ†æ•°æ˜ å°„ï¼ˆç”¨äºè®¡ç®—ç›¸å…³æ€§ï¼‰
        self.label_to_score = {'E': 1.0, 'S': 0.8, 'C': 0.3, 'I': 0.0}
    
    def prepare_dataset(self, esci_data):
        """
        å‡†å¤‡è®­ç»ƒæ•°æ®
        ä»ESCIæ•°æ®é›†æ„å»º(query, product_title, label)ä¸‰å…ƒç»„
        """
        train_examples = []
        
        for item in esci_data['train']:
            train_examples.append({
                'query': item['query'],
                'product_title': item['product_title'],
                'label': self.label_to_id[item['esci_label']]
            })
        
        # è½¬ä¸ºHugging Face Dataset
        dataset = Dataset.from_list(train_examples)
        
        def tokenize_function(examples):
            # è¾“å…¥æ ¼å¼: [CLS] query [SEP] product_title [SEP]
            return self.tokenizer(
                examples['query'],
                examples['product_title'],
                truncation=True,
                padding='max_length',
                max_length=128
            )
        
        tokenized = dataset.map(tokenize_function, batched=True)
        tokenized = tokenized.rename_column("label", "labels")
        
        # åˆ’åˆ†train/val
        split = tokenized.train_test_split(test_size=0.1, seed=42)
        
        return split['train'], split['test']
    
    def train(self, train_dataset, val_dataset, output_dir="./checkpoints/relevance_scorer"):
        """è®­ç»ƒç›¸å…³æ€§è¯„åˆ†å™¨"""
        print("\nğŸ¯ è®­ç»ƒç›¸å…³æ€§è¯„åˆ†æ¨¡å‹...")
        
        training_args = TrainingArguments(
            output_dir=output_dir,
            num_train_epochs=3,
            per_device_train_batch_size=32,
            per_device_eval_batch_size=64,
            learning_rate=2e-5,
            warmup_steps=500,
            weight_decay=0.01,
            logging_steps=100,
            evaluation_strategy="steps",
            eval_steps=500,
            save_steps=1000,
            save_total_limit=2,
            fp16=True,  # æ··åˆç²¾åº¦åŠ é€Ÿ
            load_best_model_at_end=True
        )
        
        trainer = Trainer(
            model=self.model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=val_dataset,
            compute_metrics=self.compute_metrics
        )
        
        trainer.train()
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        self.model.save_pretrained(output_dir)
        self.tokenizer.save_pretrained(output_dir)
        
        print(f"âœ“ æ¨¡å‹å·²ä¿å­˜åˆ°: {output_dir}")
        
        return trainer
    
    def compute_metrics(self, eval_pred):
        """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
        logits, labels = eval_pred
        predictions = np.argmax(logits, axis=-1)
        
        accuracy = (predictions == labels).mean()
        
        return {"accuracy": accuracy}
    
    def score(self, query: str, product_title: str) -> float:
        """
        ç»™query-productå¯¹æ‰“åˆ†
        
        Returns:
            0-1ä¹‹é—´çš„ç›¸å…³æ€§åˆ†æ•°
        """
        self.model.eval()
        
        inputs = self.tokenizer(
            query,
            product_title,
            return_tensors='pt',
            truncation=True,
            padding='max_length',
            max_length=128
        ).to(self.device)
        
        with torch.no_grad():
            outputs = self.model(**inputs)
            probs = torch.softmax(outputs.logits, dim=-1)
            predicted_label_id = torch.argmax(probs, dim=-1).item()
        
        # è½¬ä¸ºæ ‡ç­¾
        predicted_label = self.id_to_label[predicted_label_id]
        
        # è¿”å›åˆ†æ•°
        return self.label_to_score[predicted_label]
    
    def batch_score(self, query: str, products: list) -> list:
        """æ‰¹é‡æ‰“åˆ†ï¼ˆæ›´é«˜æ•ˆï¼‰"""
        self.model.eval()
        
        scores = []
        
        # æ‰¹é‡å¤„ç†
        batch_size = 32
        for i in range(0, len(products), batch_size):
            batch_products = products[i:i+batch_size]
            
            inputs = self.tokenizer(
                [query] * len(batch_products),
                [p['title'] for p in batch_products],
                return_tensors='pt',
                truncation=True,
                padding=True,
                max_length=128
            ).to(self.device)
            
            with torch.no_grad():
                outputs = self.model(**inputs)
                probs = torch.softmax(outputs.logits, dim=-1)
                predicted_labels = torch.argmax(probs, dim=-1)
            
            # è½¬ä¸ºåˆ†æ•°
            for label_id in predicted_labels:
                label = self.id_to_label[label_id.item()]
                scores.append(self.label_to_score[label])
        
        return scores
    
    @classmethod
    def load_pretrained(cls, model_path: str):
        """åŠ è½½å·²è®­ç»ƒçš„æ¨¡å‹"""
        scorer = cls()
        scorer.model = BertForSequenceClassification.from_pretrained(model_path).to(scorer.device)
        scorer.tokenizer = BertTokenizer.from_pretrained(model_path)
        print(f"âœ“ åŠ è½½æ¨¡å‹: {model_path}")
        return scorer


# ============ æµ‹è¯•ä»£ç  ============
if __name__ == "__main__":
    from data.download_esci import download_esci_dataset
    
    # ä¸‹è½½æ•°æ®
    dataset = download_esci_dataset()
    
    # åˆå§‹åŒ–scorer
    scorer = RelevanceScorer()
    
    # å‡†å¤‡æ•°æ®
    train_data, val_data = scorer.prepare_dataset(dataset)
    
    # è®­ç»ƒ
    scorer.train(train_data, val_data)
    
    # æµ‹è¯•
    test_query = "summer dress"
    test_product = "Women's Floral Maxi Summer Dress"
    score = scorer.score(test_query, test_product)
    print(f"\næµ‹è¯•ç›¸å…³æ€§:\nQuery: {test_query}\nProduct: {test_product}\nScore: {score:.3f}")