"""
å®Œæ•´è¯„ä¼°æµç¨‹
"""

import json
from tqdm import tqdm
import random
from evaluation.metrics import Metrics
from models.relevance_scorer import RelevanceScorer
from utils.elasticsearch_utils import ElasticsearchClient
from utils.llm_api import LLMClient
from training.online_dpo import generate_user_profiles

class Evaluator:
    def __init__(self, 
                 model,
                 tokenizer,
                 config: dict,
                 use_llm_feedback: bool = True):
        """åˆå§‹åŒ–è¯„ä¼°å™¨"""
        self.model = model
        self.tokenizer = tokenizer
        self.config = config
        
        # åŠ è½½è¾…åŠ©æ¨¡å—
        self.metrics = Metrics()
        self.relevance_scorer = RelevanceScorer.load_pretrained(
            "./checkpoints/relevance_scorer"
        )
        self.es_client = ElasticsearchClient()
        
        if use_llm_feedback:
            self.llm_client = LLMClient()
        else:
            self.llm_client = None
        
        # ç”Ÿæˆç”¨æˆ·ç”»åƒ
        self.user_profiles = generate_user_profiles(50)
    
    def evaluate_offline(self, test_data: list) -> dict:
        """
        ç¦»çº¿è¯„ä¼°ï¼ˆåŸºäºQ2Qæ•°æ®é›†ï¼‰
        
        Metrics: ExactMatch, RougeL, CrossEntropy
        """
        print("\nğŸ“Š ç¦»çº¿è¯„ä¼°...")
        
        predictions = []
        references = []
        
        for item in tqdm(test_data[:100], desc="Generating"):
            query = item['query']
            reference = item['rewritten_query']
            
            # ç”Ÿæˆæ”¹å†™
            input_text = f"rewrite query: {query}"
            inputs = self.tokenizer(input_text, return_tensors='pt').to(self.model.device)
            
            outputs = self.model.generate(**inputs, max_length=128)
            prediction = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            predictions.append(prediction)
            references.append(reference)
        
        # è®¡ç®—æŒ‡æ ‡
        results = {
            'exact_match': self.metrics.exact_match(predictions, references),
            'rouge_l': self.metrics.rouge_l(predictions, references)
        }
        
        print(f"âœ“ ExactMatch: {results['exact_match']:.4f}")
        print(f"âœ“ RougeL: {results['rouge_l']:.4f}")
        
        return results
    
    def evaluate_online(self, test_queries: list, num_rewrites: int = 10) -> dict:
        """
        åœ¨çº¿è¯„ä¼°
        
        Metrics: Product Coverage, Relevance, Diversity, User Feedback
        """
        print("\nğŸ“Š åœ¨çº¿è¯„ä¼°...")
        
        all_covered_products = []
        relevance_scores = []
        diversity_scores = []
        click_rates = []
        add_to_cart_rates = []
        purchase_rates = []
        
        for query in tqdm(test_queries, desc="Evaluating"):
            # 1. ç”Ÿæˆå¤šä¸ªæ”¹å†™
            input_text = f"rewrite query: {query}"
            inputs = self.tokenizer(input_text, return_tensors='pt').to(self.model.device)
            
            outputs = self.model.generate(
                **inputs,
                max_length=128,
                num_return_sequences=num_rewrites,
                do_sample=True,
                temperature=0.8
            )
            
            rewrites = [
                self.tokenizer.decode(output, skip_special_tokens=True)
                for output in outputs
            ]
            
            # 2. å¯¹æ¯ä¸ªæ”¹å†™è®¡ç®—æŒ‡æ ‡
            original_products = self.es_client.search(query)
            
            for rewrite in rewrites:
                rewritten_products = self.es_client.search(rewrite)
                
                if len(rewritten_products) == 0:
                    continue
                
                # å•†å“è¦†ç›–
                all_covered_products.extend(rewritten_products)
                
                # ç›¸å…³æ€§
                relevance = self.metrics.relevance_score(
                    query,
                    rewritten_products,
                    self.relevance_scorer
                )
                relevance_scores.append(relevance)
                
                # å¤šæ ·æ€§
                diversity = self.metrics.diversity_score(
                    original_products,
                    rewritten_products
                )
                diversity_scores.append(diversity)
                
                # ç”¨æˆ·åé¦ˆï¼ˆå¯é€‰ï¼‰
                if self.llm_client:
                    user_profile = random.choice(self.user_profiles)
                    feedback = self.metrics.user_feedback_scores(
                        query,
                        rewritten_products,
                        user_profile,
                        self.llm_client
                    )
                    click_rates.append(feedback['click_rate'])
                    add_to_cart_rates.append(feedback['add_to_cart_rate'])
                    purchase_rates.append(feedback['purchase_rate'])
        
        # æ±‡æ€»ç»“æœ
        results = {
            'product_coverage': len(set([p['product_id'] for p in all_covered_products])),
            'relevance': sum(relevance_scores) / len(relevance_scores) if relevance_scores else 0,
            'diversity': sum(diversity_scores) / len(diversity_scores) if diversity_scores else 0
        }
        
        if self.llm_client:
            results.update({
                'click_rate': sum(click_rates) / len(click_rates) if click_rates else 0,
                'add_to_cart_rate': sum(add_to_cart_rates) / len(add_to_cart_rates) if add_to_cart_rates else 0,
                'purchase_rate': sum(purchase_rates) / len(purchase_rates) if purchase_rates else 0
            })
        
        # æ‰“å°ç»“æœ
        print(f"âœ“ Product Coverage: {results['product_coverage']}")
        print(f"âœ“ Relevance: {results['relevance']:.4f}")
        print(f"âœ“ Diversity: {results['diversity']:.4f}")
        
        if self.llm_client:
            print(f"âœ“ Click Rate: {results['click_rate']:.4f}")
            print(f"âœ“ Add-to-Cart Rate: {results['add_to_cart_rate']:.4f}")
            print(f"âœ“ Purchase Rate: {results['purchase_rate']:.4f}")
        
        return results
    
    def save_results(self, results: dict, output_path: str):
        """ä¿å­˜è¯„ä¼°ç»“æœ"""
        with open(output_path, 'w') as f:
            json.dump(results, f, indent=2)
        print(f"\nâœ“ ç»“æœå·²ä¿å­˜åˆ°: {output_path}")


# ============ æµ‹è¯•ä»£ç  ============
if __name__ == "__main__":
    print("è¯·ä½¿ç”¨run_pipeline.pyè¿è¡Œå®Œæ•´è¯„ä¼°")